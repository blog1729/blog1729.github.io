<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Blog1729 - 2015-09-08-stochastic-calculus</title>
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
	  tex2jax: {
	  inlineMath: [ ['$','$'], ["\\(","\\)"] ],
	  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
	  processEscapes: true
	  },
	  TeX: {
	  Macros: {
	  R: "\\mathbb{R}",
	  C: "\\mathbb{C}"
	  }}	  
	  });
	</script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="../">Blog1729</a>
            </div>
            <div id="navigation">
                <a href="../">Home</a>
                <a href="../about.html">About</a>
                <a href="../contact.html">Contact</a>
                <a href="../archive.html">Archive</a>
            </div>
        </div>

        <div id="content">
            <h1>2015-09-08-stochastic-calculus</h1>

            <div class="info">
    Posted on September  8, 2015
    
</div>

<h1>General Probability theory</h1>
<ul>
<li><p>Probability can be thought of as a set function (measure?) that satisfies the following conditions:</p>
<ol>
<li><span class="math inline">\(\P(A) \in [0, 1]\)</span> for elements in the sigma algebra <span class="math inline">\(\F\)</span>.</li>
<li><span class="math inline">\(\P(\Omega) = 1\)</span>, here <span class="math inline">\(\Omega\)</span> is the entire space.</li>
<li>Let <span class="math inline">\(\{A_i\}\)</span> be pairwise disjoint subsets of <span class="math inline">\(\F\)</span>, then <span class="math inline">\(\P(\cup A_i) = \sum \P(A_i)\)</span>.</li>
</ol></li>
<li><p>Compare the above definition with that of a measure <span class="math inline">\(\mu\)</span> on a measure space <span class="math inline">\(\Omega\)</span>.</p>
<ol>
<li>Positive, i.e., <span class="math inline">\(\mu(A) \ge 0\)</span>.</li>
<li>Countable additivity.</li>
</ol></li>
<li><p>Thus the probability is indeed a measure!</p></li>
<li><p>In a probability space, a random variable is a measurable function. (There are other definitions for this. For example, a real valued function <span class="math inline">\(X\)</span> from the sigma algebra <span class="math inline">\(\F\)</span> is said to be a random variable if for every Borel set <span class="math inline">\(B\)</span>, the set <span class="math inline">\(\{X \in
 B\}\)</span> is in the sigma algebra <span class="math inline">\(\F\)</span>.)</p></li>
<li><p>The expectation of the random variable <span class="math inline">\(X\)</span> is the Lebesgue integral <span class="math inline">\(\int X d\P\)</span>.</p></li>
<li><p>The conditional probability <span class="math inline">\(\P(A \vert B)\)</span> is given by the fraction <span class="math inline">\(\frac{\P(A \cap B)}{\P(B)}\)</span>.</p></li>
<li><p>If <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are positive constants, then <span class="math inline">\(E(\alpha X + \beta Y) = \alpha EX + \beta EY\)</span>.</p></li>
</ul>
<h1>Information and Conditioning</h1>
<ul>
<li><p>We say that two sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> in <span class="math inline">\(\F\)</span> are independent if <span class="math inline">\(P(A\cap B) = P(A) P(B)\)</span>. Clearly, the independence depends on the probability measure too.</p></li>
<li><p>Similarly, if <span class="math inline">\(\F\)</span> be a sigma algebra and if <span class="math inline">\(\G\)</span> and <span class="math inline">\(\mathcal H\)</span> be two sub sigma algebra. Then <span class="math inline">\(\G\)</span> and <span class="math inline">\(\mathcal H\)</span> are said to be independent if for every <span class="math inline">\(A \in \G\)</span> and every <span class="math inline">\(B \in \mathcal H\)</span>, <span class="math inline">\(P(A \cap B) = P(A) P(B)\)</span>.</p></li>
<li><p>Sigma algebra generated by <span class="math inline">\(X\)</span>: If <span class="math inline">\(X\)</span> is a random variable, then the sigma algebra generated by <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\sigma(X)\)</span> is the collection of all subsets of the form <span class="math inline">\(X^{-1}(B)\)</span> where <span class="math inline">\(B\)</span> ranges over the Borel sigma algebra.</p></li>
<li><p><strong>G-measurable</strong>: G be a sigma algebra on <span class="math inline">\(\Omega\)</span> and if every set of <span class="math inline">\(\sigma(X)\)</span> is an element of <span class="math inline">\(\G\)</span>, then <span class="math inline">\(X\)</span> is said to be <span class="math inline">\(\G\)</span>-measurable.</p></li>
<li><p><strong>Conditional expectation</strong>. In a probability space, let <span class="math inline">\(\G\)</span> be a sub sigma algebra of <span class="math inline">\(\F\)</span> and let <span class="math inline">\(X\)</span> be a random variable that is either non-negative or integrable. Then the conditional expectation of <span class="math inline">\(X\)</span> given <span class="math inline">\(\G\)</span>, denoted by <span class="math inline">\(E[X \vert G]\)</span>, is any random variable that satisfies.</p>
<ol>
<li>(<strong>Measurability</strong>): <span class="math inline">\(E[X\vert G]\)</span> is <span class="math inline">\(\G\)</span>-measurable, and</li>
<li>(<strong>Partial Averaging</strong>): <span class="math display">\[\int_A E[X\vert G]\,d\P =
 \int_AX\,d\P \, \text{ for all } A \in \G.\]</span></li>
</ol>
<p>If <span class="math inline">\(\G\)</span> is a <span class="math inline">\(\sigma\)</span> algebra generated by a random variable <span class="math inline">\(W\)</span>, we generally write <span class="math inline">\(E[X\vert W]\)</span> rather than <span class="math inline">\(E[X \vert\sigma(W)]\)</span> or <span class="math inline">\(\E[X\vert \G]\)</span>.</p>
<p>Define <span class="math inline">\(\tP\)</span> by <span class="math inline">\(\tP(A) = \int_A \frac{X + 1}{\E[X + 1]} d\P\)</span>. Define <span class="math inline">\(\Q\)</span> and <span class="math inline">\(\tQ\)</span> by restricting <span class="math inline">\(\P\)</span> and <span class="math inline">\(\tP\)</span> on the sigma algebra <span class="math inline">\(\G\)</span>. Let <span class="math inline">\(Z\)</span> denote the random variable <span class="math inline">\(\frac{d\tQ}{d\Q}\)</span>.</p>
<p>Then the random variable <span class="math inline">\((Z \cdot \E[X + 1]  - 1) = \E[X\vert \G]\)</span>.</p></li>
<li><p>When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are discrete random variables, the conditional expectation <span class="math inline">\(\E[X\vert Y]\)</span> is the function given by</p>
<p><span class="math display">\[\E[X\vert Y = y] = \sum_{x \in \chi} x \P(X = x \vert Y = y) = \sum_{x\in X} x \cdot \frac{\P(X = x, Y = y)}{\P(Y = y)}.\]</span></p></li>
<li><p><strong>Theorem</strong></p>
<p>Let <span class="math inline">\((\Omega, \F, \P)\)</span> be a probability space and let <span class="math inline">\(\G\)</span> be a sub sigma-algebra of <span class="math inline">\(\F\)</span>.</p>
<ol>
<li><p>(<strong>Linearity of Conditional Expectation</strong>.) If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are integrable random variables and <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> are constants, then</p>
<p><span class="math display">\[\E[(c_1X + c_2Y)\vert \G] = c_1\E[X\vert \G] + c_2\E[X\vert \G].\]</span></p></li>
<li><p>(<strong>Taking out what is known</strong>.) If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are integrable random variables, <span class="math inline">\(Y\)</span> and <span class="math inline">\(XY\)</span> are integrable, and <span class="math inline">\(X\)</span> is <span class="math inline">\(\G\)</span>-measurable, then</p>
<p><span class="math display">\[\E[XY\vert \G] = X\E[Y\vert \G].\]</span></p></li>
<li><p>(<strong>Iterated Conditioning</strong> or <strong>Tower property</strong>) If <span class="math inline">\(H\)</span> is a sub-sigma algebra of <span class="math inline">\(\G\)</span> and <span class="math inline">\(X\)</span> is an integrable random variable, then</p>
<p><span class="math display">\[ \E[\E[X\vert \G]\vert {\mathcal H}] = \E[ X\vert\mathcal H].\]</span></p></li>
<li><p>(<strong>Independence</strong>.) If <span class="math inline">\(X\)</span> is integrable and independent of <span class="math inline">\(\G\)</span>, then</p>
<p><span class="math display">\[\E[X\vert \G] = \E X.\]</span></p></li>
<li><p>(<strong>Conditional Jensen’s inequality</strong>.) If <span class="math inline">\(\varphi(x)\)</span> is a convex function and if <span class="math inline">\(X\)</span> is integrable, then</p>
<p><span class="math display">\[\E[\varphi(X)\vert \G] \ge \varphi(E[X\vert \G]).\]</span></p></li>
</ol></li>
</ul>
<h1>Martingales</h1>
<ul>
<li><p><strong>Definition</strong>: Let <span class="math inline">\(\{X_n\}\)</span> be a stochastic process and <span class="math inline">\(\{\F_n\}\)</span> be a filtration such that <span class="math inline">\(X_n\)</span> is adapted with respect to <span class="math inline">\(\F_n\)</span>, (this means that <span class="math inline">\(X_n\)</span> is <span class="math inline">\(\F_n\)</span> measurable) then we say that <span class="math inline">\(X_n\)</span> is a martingale, when</p>
<ol>
<li><span class="math inline">\(\E[X_n] &lt; \infty\)</span></li>
<li><span class="math inline">\(\E[X_{n+1}|\F_n] = X_n\)</span> for all values of <span class="math inline">\(n\)</span>.</li>
</ol></li>
<li><p>If the equality in the 2nd condition is replaced by less than or equal to sign, then the process is called <strong>supermartingale</strong>.</p>
<p>Similarly, if the equality is replaced by greater than or equal to sign, then the process is called as <strong>submartingale</strong>.</p></li>
<li><p>It should be noted, that in our definition, the indexing set is countable, but this need not be the case, in general. The definition can be naturally extended for arbitrary indexing sets.</p></li>
<li><p>Examples: random walks (?), a gambler’s fortune (assuming that all the games that he is playing is a fair game.)</p></li>
<li><p>In case of a binomial model, we can think of two probability measures on the same sample space. One of them is the natural probability measure or the one that assigns probability <span class="math inline">\(p\)</span> to an uptick scenario and <span class="math inline">\(q\)</span> to a down-tick scenario. The second one is more of a constructed probability measure and is called as “risk neutral probability”. This has an uptick probability <span class="math inline">\(\tilde{p}\)</span> and down-tick probability <span class="math inline">\(\tilde{q}\)</span>.</p>
<p>Here <span class="math display">\[\tilde{p} = \frac{1 + r - d}{u - d},\]</span> and <span class="math display">\[\tilde{q} =
 \frac{u - 1 - r}{u-d}.\]</span></p>
<p>If the value of the asset at time <span class="math inline">\(n\)</span> is given by <span class="math inline">\(S_n\)</span>, then we can see that <span class="math display">\[ \frac{S_n}{(1+r)^n} =
 \tilde{\mathbb{E}}_N\left[\frac{S_{n+1}}{(1+r)^{n+1}}\right].\]</span></p>
<p>The last conclusion shows that (?) the random variable <span class="math inline">\(\frac{S_n}{(1+r)^n}\)</span> is a martingale. (<strong>Note</strong>: What Shreve means by <span class="math inline">\(\tE_n[X]\)</span> is the conditional expectation <span class="math inline">\(\E[X\vert F_n]\)</span> where <span class="math inline">\(F_n\)</span> is the sigma algebra corresponding to <span class="math inline">\(n\)</span> coin tosses.)</p></li>
<li><p><strong>Theorem</strong> Consider a binomial model with <span class="math inline">\(N\)</span> periods. If <span class="math inline">\(\Delta_0, \cdots, \Delta_{N-1}\)</span> be an adapted portfolio process, let <span class="math inline">\(X_0\)</span> be a real number, and let wealth process <span class="math inline">\(X_1, \cdots,
 X_N\)</span> be generated by the equation:</p>
<p><span class="math display">\[X_{n+1} = \Delta_n S_{n+1} + (1 + r)(X_n - \Delta_n S_n), n = 0,
 1, \cdots, N-1.\]</span></p>
<p>Then the discounted wealth process <span class="math inline">\(\frac{X_n}{(1+r)^n}\)</span> is a martingale under the risk-neutral measure, i.e.,</p>
<p><span class="math display">\[\frac{X_n}{(1+r)^n} =
 \tilde{\mathbb{E}}_n\left[\frac{X_{n+1}}{(1+r)^{n+1}}\right].\]</span></p></li>
</ul>
<h1>Relevant Measure theory</h1>
<ul>
<li><p><strong>Signed measures</strong> are real valued set functions.</p></li>
<li><p>We say that a set <span class="math inline">\(A^{\plus}\)</span> is positive w.r.t. to a signed measure <span class="math inline">\(v\)</span> if <span class="math inline">\(v(A^{\plus} \cap E) \ge 0\)</span> for all <span class="math inline">\(E \in \chi\)</span>.</p>
<p>Similarly, we can define what it means to call a set negative.</p></li>
<li><p><strong>Hahn Decomposition theorem</strong>. One can decompose the measurable space into disjoint positive and negative sets.</p>
<p>It can be shown that this decomposition, in some sense, is unique. More precisely, if <span class="math inline">\(\{A_1^{\plus}, A_1^{-}\}\)</span> and <span class="math inline">\(\{A_2^{\plus}, A_2^{\plus}\}\)</span> are two such decomposition, then for all <span class="math inline">\(E \in \chi\)</span>, <span class="math inline">\(v(A_1^{\plus} \cap E) = v(A_2^{\plus} \cap E)\)</span> and similarly for the negative part too.</p></li>
<li><p>For a signed measure <span class="math inline">\(v\)</span>, we can define measure <span class="math inline">\(v^{\plus}\)</span> and <span class="math inline">\(v^{-}\)</span> by:</p>
<p><span class="math display">\[\begin{array}{cl}
 v^{\plus}(E) &amp;= v(A^{\plus} \cap E)\\
 v^{-}(E) &amp;= v(A^{-} \cap E)\\\end{array}\]</span></p></li>
<li><p><strong>Jordan decomposition theorem</strong>. For a signed measure <span class="math inline">\(v\)</span>, <span class="math inline">\(v =
 v^{\plus} - v^{-}\)</span> and if <span class="math inline">\(v = \lambda - \mu\)</span>, then <span class="math inline">\(v^{\plus}
 \le \lambda\)</span> and <span class="math inline">\(v^{-} \le \mu\)</span>. (Here <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> are positive measures.)</p></li>
<li><p>The total variation of a signed measure <span class="math inline">\(v\colon \chi \rightarrow
 \R\)</span> is a finite measure <span class="math inline">\(\vert v \vert \colon \chi \rightarrow
 \R\)</span> defined by <span class="math inline">\(\vert v \vert = v^{\plus} + v^{-}\)</span>.</p></li>
<li><p>If <span class="math inline">\((X, \chi, \mu)\)</span> is a measure space, <span class="math inline">\(f \in L(X, \chi, \mu)\)</span> and <span class="math inline">\(v\colon \chi \rightarrow \R\)</span> is the signed measure defined by</p>
<p><span class="math display">\[v(E) = \int_{E} f d \mu.\]</span></p>
<p>Then the negative, the positive and the total variation are given by</p>
<p><span class="math display">\[v^{\plus}(E) = \int_{E} f^{+} d\mu\]</span></p>
<p><span class="math display">\[v^{-}(E) = \int_{E} f^{-} d\mu\]</span></p>
<p><span class="math display">\[\bar{v}(E) = \int_{E} \vert f \vert d \mu.\]</span></p></li>
<li><p>Let <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> be measures on <span class="math inline">\(\chi\)</span>, we say that <span class="math inline">\(\lambda\)</span> is absolutely continuous with respect to <span class="math inline">\(\mu\)</span> if for every set <span class="math inline">\(E\)</span> such that <span class="math inline">\(\lambda(E) = 0\)</span> the value of <span class="math inline">\(\mu(E)\)</span> is also zero. We use the notation <span class="math inline">\(\lambda \ll \mu\)</span> to denote the same.</p></li>
<li><p><strong>Theorem</strong>. <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> be measures on <span class="math inline">\(\chi\)</span>, then the following two statements are equivalent.</p>
<ol>
<li><p>For every <span class="math inline">\(\varepsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> such that, for <span class="math inline">\(E \in \chi\)</span>, <span class="math inline">\(\mu(E) &lt; \delta\)</span> implies <span class="math inline">\(\lambda(E)
 &lt; \varepsilon\)</span>.</p></li>
<li><p><span class="math inline">\(\lambda\)</span> is absolutely continuous with respect to <span class="math inline">\(\mu\)</span> (<span class="math inline">\(\lambda \ll \mu\)</span>.)</p></li>
</ol></li>
<li><p><strong>Radon Nikodym Theorem</strong>.</p>
<p><span class="math inline">\((X, \chi, \mu)\)</span> be a measurable space and <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> be <span class="math inline">\(\sigma\)</span>-finite measures on <span class="math inline">\(\chi\)</span>. If <span class="math inline">\(\lambda\)</span> is absolutely continuous with respect to <span class="math inline">\(\mu\)</span>, then there exists a unique (<span class="math inline">\(\mu\)</span> a.e.) real valued measurable function <span class="math inline">\(f\)</span> such that</p>
<p><span class="math display">\[\lambda(E) = \int_{E} f d\mu.\]</span></p>
<p>The function <span class="math inline">\(f\)</span> is called as the <strong>Radon-Nikodym derivative</strong> of <span class="math inline">\(\lambda\)</span> with respect to <span class="math inline">\(\mu\)</span> and is denoted by <span class="math inline">\(f = \frac{d
 \lambda}{d\mu}\)</span>.</p></li>
<li><p>The Radon Nikodym theorem is vital in proving the existence of the conditional expectation. (For a proof, refer to Appendix B: Existence of Conditional Expectation in Shreve Vol II.)</p></li>
</ul>
<h1>State Prices</h1>
<ul>
<li><p>Consider a finite sample space <span class="math inline">\(\Omega\)</span> on which we have two probability measures <span class="math inline">\(\P\)</span> and <span class="math inline">\(\tP\)</span>. If <span class="math inline">\(\P\)</span> and <span class="math inline">\(\tP\)</span> both give positive probability to every element of <span class="math inline">\(\Omega\)</span>, observe that as per our definition <span class="math inline">\(\P\)</span> and <span class="math inline">\(\tP\)</span> are equivalent.</p>
<p>In this case, one can see that the Radon-Nikodym derivative <span class="math inline">\(\frac{d\tP}{d\P}\)</span> is given by the random variable <span class="math inline">\(Z\)</span> given by <span class="math inline">\(Z(\omega) = \frac{\tP(\omega)}{\P(\omega)}\)</span>.</p></li>
<li><p><strong>Theorem</strong>. Let <span class="math inline">\(\P\)</span> and <span class="math inline">\(\tP\)</span> be probability measures on finite sample space <span class="math inline">\(\Omega\)</span>, and assume that <span class="math inline">\(\P(\omega) &gt; 0\)</span> and <span class="math inline">\(\tP(\omega) &gt; 0\)</span> for every <span class="math inline">\(\omega \in \Omega\)</span>, and define the random variable <span class="math inline">\(Z\)</span> to be the Radon-Nikodym derivative (defined in the previous bullet.) Then we have the following:</p>
<ol>
<li><p><span class="math inline">\(\P(Z &gt; 0) = 1\)</span>.</p></li>
<li><p><span class="math inline">\(\E Z = 1\)</span></p></li>
<li><p>for any random variable <span class="math inline">\(Y\)</span>,</p>
<p><span class="math display">\[\tE Y = \E[ZY].\]</span></p></li>
</ol></li>
</ul>
<h1>Change of Measure</h1>
<ul>
<li><p>In stochastic calculus, we say that two measures <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> are equivalent if</p>
<p><span class="math display">\[ \lambda(E) = 0 \iff \mu(E) = 0.\]</span></p>
<p>Notice that this is absolutely continuous in “both directions”.</p></li>
<li><p><strong>Theorem</strong>. Let <span class="math inline">\((\Omega, F, \P)\)</span> be a probability space and let <span class="math inline">\(Z\)</span> be an almost surely nonnegative random variable with <span class="math inline">\(\E Z = 1\)</span>. For <span class="math inline">\(A \in \F\)</span>, define</p>
<p><span class="math display">\[\tP(A) = \int_A Z d\P.\]</span></p>
<p>Then <span class="math inline">\(\tP\)</span> is a probability measure. Furthermore, if <span class="math inline">\(X\)</span> is a nonnegative random variable, then</p>
<p><span class="math display">\[\tE(X) = \E[XZ].\]</span></p>
<p>If <span class="math inline">\(Z\)</span> is almost surely strictly positive, we also have</p>
<p><span class="math display">\[\E Y = \tE \left[ \frac{Y}{Z}\right].\]</span></p></li>
<li><p>It should noted that for two probability measures <span class="math inline">\(\P\)</span> and <span class="math inline">\(\tP\)</span> that are equivalent, the Radon-Nikodym theorem guarantees you the existence of such a random variable <span class="math inline">\(Z\)</span>.</p></li>
</ul>
<h1>Independence</h1>
<ul>
<li><p>Let <span class="math inline">\((\Omega, \F, \P)\)</span> be a probability space, we say that two sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if</p>
<p><span class="math display">\[\P(A \cap B) = \P(A) \cap \P(B).\]</span></p>
<p>We say that two sigma algebras <span class="math inline">\(\F\)</span> and <span class="math inline">\(\G\)</span> are independent if for <span class="math inline">\(A \in \F\)</span> and <span class="math inline">\(B \in \G\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent.</p>
<p>We say that two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent if <span class="math inline">\(\sigma(X)\)</span> and <span class="math inline">\(\sigma(Y)\)</span> are independent.</p>
<p>We use the notation <span class="math inline">\(\E[Y\vert X]\)</span> where <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are random variables to denote <span class="math inline">\(\E[Y\vert \sigma(X)]\)</span>, also, we use the notation <span class="math inline">\(f(X)\)</span>, where <span class="math inline">\(f\)</span> is usually a Borel Measurable function to denote the function <span class="math inline">\(f \circ X\colon \Omega \rightarrow \R\)</span>.</p></li>
<li><p><strong>Theorem</strong>: Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be independent random variables, and let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be Borel measurable functions on <span class="math inline">\(\R\)</span>. Then <span class="math inline">\(f(X)\)</span> and <span class="math inline">\(g(Y)\)</span> are independent random variables.</p>
<p><em>Proof</em>: Notice that <span class="math inline">\(f(X)\)</span> and <span class="math inline">\(g(Y)\)</span> are measurable. The theorem follows from the fact that the sigma algebra generated by <span class="math inline">\(f(X)\)</span> and <span class="math inline">\(g(Y)\)</span> are a sub-sigma algebra of <span class="math inline">\(\sigma(X)\)</span> and <span class="math inline">\(\sigma(Y)\)</span> respectively.</p></li>
<li><p>We can define a Borel sigma algebra on <span class="math inline">\(\R^2\)</span> by taking the sigma algebra generated by closed rectangles in <span class="math inline">\(\R^2\)</span>.</p></li>
<li><p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be random variables. The pair of random variables <span class="math inline">\((X, Y)\)</span> takes values in the place <span class="math inline">\(\R^2\)</span>, and the joint distribution measure of <span class="math inline">\((X, Y)\)</span> is given by</p>
<p><span class="math display">\[\mu_{X, Y}(C) = \P\{(X, Y) \in C\} \text{ for all Borel sets } C
 \subset \R^2.\]</span></p>
<p>One can see that this (<span class="math inline">\(\mu\)</span>) is a probability measure.</p>
<p>The joint cumulative distribution function of <span class="math inline">\((X, Y)\)</span> is:</p>
<p><span class="math display">\[F_{X, Y}(a, b) = \mu_{X, Y}((-\infty, a] \times (\infty, b]) =
 \P\{X \le a, Y\le b\}, a \in \R, b\in \R.\]</span></p>
<p>We say that a nonnegative, Borel-measurable function <span class="math inline">\(f_{X, Y}(x,
 y)\)</span> is a joint density for a pair of random variables if</p>
<p><span class="math display">\[\mu_{X, Y}(C) = \iint \chi_C(x, y) f_{X, Y}\, dydx.\]</span></p>
<p>The marginal distribution function <span class="math inline">\(\mu_X\)</span> can be defined by</p>
<p><span class="math display">\[\mu_X(A) = \P(\{X \in A \}\times \R).\]</span></p>
<p>and <span class="math inline">\(\mu_Y\)</span> can be similarly defined. Similarly, we can think of marginal densities.</p>
<p>Some observations:</p>
<ul>
<li>Essentially, we are defining a probability measure on <span class="math inline">\(\Omega_1
 \times \Omega_2\)</span>, with the help of two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> on <span class="math inline">\(\Omega_1\)</span> and <span class="math inline">\(\Omega_2\)</span> respectively.</li>
</ul></li>
<li><p><strong>Theorem</strong>. Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be random variables. The following conditions are equivalent.</p>
<ol>
<li><p><span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent.</p></li>
<li><p>The joint distribution measure factors (for all Borel sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>)</p>
<p><span class="math display">\[\mu_{X, Y}(A, B) = \mu_X(A) \cdot \mu_Y(B).\]</span></p></li>
<li><p>The joint cumulative distribution function factors:</p>
<p><span class="math display">\[F_{X, Y}(a, b) = F_X(a) \cdot F_Y(b).\]</span></p></li>
<li><p>The joint moment-generating function factors:</p>
<p><span class="math display">\[\E e^{uX + uY} = \E e^{uX} \cdot \E e^{vY}.\]</span></p>
<p>for all <span class="math inline">\(u, v \in \R\)</span>, for which the expectations are finite.</p>
<p><strong>If there is a joint density</strong>, each of the conditions are equivalent to the following (in the general case, the above <strong>conditions imply</strong> the following:)</p></li>
<li><p>The joint density factors:</p>
<p><span class="math display">\[f_{X, Y}(x, y) = f_X(x) \cdot f_Y(y).\]</span></p>
<p>for almost every <span class="math inline">\(x\in \R\)</span> and <span class="math inline">\(y\in \R\)</span>.</p></li>
<li><p>The expectation factors</p>
<p><span class="math display">\[\E[XY] = \E X \cdot\E Y,\]</span></p>
<p>provided that <span class="math inline">\(\E[XY] &lt; \infty\)</span>.</p></li>
</ol></li>
<li><p>The <strong>variance</strong> of a random variable <span class="math inline">\(X\)</span> whose expected value is defined, denoted by <span class="math inline">\(\Var(X)\)</span></p>
<p><span class="math display">\[\Var(X) = \E[(X - \E X)^2] = \E[X^2] - \E[X]^2.\]</span></p>
<p>The <strong>standard deviation</strong> is defined as <span class="math inline">\(\sqrt{\Var(X)}\)</span>.</p>
<p>The <strong>covariance</strong> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[\Cov(X, Y) = \E[(X - \E X)(Y - \E Y)] = \E[XY] - \E X \cdot \E Y.\]</span></p>
<p>In particular, <span class="math inline">\(\E[XY] = \E X \cdot E Y = 0 \iff \Cov(X, Y) = 0\)</span>. The <strong>correlation coefficient</strong> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is</p>
<p><span class="math display">\[\rho(X, Y) = \frac{\Cov(X, Y)}{\sqrt{\Var(X) \Var(Y)}}.\]</span></p></li>
<li><p>Example of an uncorrelated dependent random variable.</p>
<p>Let <span class="math inline">\(X\)</span> be the standard normal random variable and choose a random variable <span class="math inline">\(Z\)</span> that is independent of <span class="math inline">\(X\)</span> and satisfying <span class="math inline">\(\P\{Z =
 1\} = \frac12\)</span> and <span class="math inline">\(\P\{Z = -1\} = \frac12\)</span>.</p>
<p>Consider the random variable <span class="math inline">\(Y = XZ\)</span>. It can be shown that this random variable is standard normal, <span class="math inline">\(\Cov(X, Y) = 0\)</span>, but <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not independent. (One can also verify that this random variable, as expected, does not have a joint density function.)</p></li>
<li><p>(<strong>Independence lemma</strong>) Let <span class="math inline">\((\Omega, \F, \P)\)</span> be a probability space, and let <span class="math inline">\(\G\)</span> be a sub-sigma-algebra of <span class="math inline">\(\F\)</span>. Suppose that the random variables <span class="math inline">\(X_1, \cdots, X_K\)</span> are <span class="math inline">\(\G\)</span>-measurable and the random variables <span class="math inline">\(Y_1, \cdots, Y_L\)</span> are independent of <span class="math inline">\(\G\)</span>. Let <span class="math inline">\(f(x_1, \cdots, x_K, y_1, \cdots, y_L)\)</span> be a function of the dummy variables <span class="math inline">\(x_1, \cdots, x_K\)</span> and <span class="math inline">\(y_1, \cdots, y_L\)</span>, and define</p>
<p><span class="math display">\[g(x_1, \cdots, x_K) = \E f(x_1, \cdots, x_K, Y_1, \cdots, Y_L).\]</span></p>
<p>Then</p>
<p><span class="math display">\[\E[f(X_1, \cdots, X_K, Y_1, \cdots, Y_L)\vert \G] = g(X_1,
 \cdots, X_K).\]</span></p></li>
</ul>
<h1>Brownian Motion</h1>
<ul>
<li><p><strong>Symmetric Random walks</strong>.</p>
<p>Let <span class="math inline">\(\omega\)</span> be an infinite sequence of tosses, and <span class="math inline">\(\omega_n\)</span> is the outcome of the <span class="math inline">\(n\)</span> th toss. Let</p>
<p><span class="math display">\[X = \left\{\begin{array}{rl} 1 &amp; \textup{if } \omega_j = H, \\
 -1 &amp; \textup{if } \omega_j = T, \end{array} \right. \]</span></p>
<p>and define <span class="math inline">\(M_0 = 0\)</span>,</p>
<p><span class="math display">\[M_k = \sum_{j=1}^{k} X_j,\ k = 1, 2, \cdots\]</span></p>
<p>(Note that in symmetric random walks, the probability of getting a head and that of heading a tail are both equal; in general random walks, this need not be true.)</p>
<p>It can be observed that, for <span class="math inline">\(0 &lt; k_1 &lt; \cdots &lt; k_m\)</span>, the random variables <span class="math inline">\((M_{k_1} - M_{k_0}), (M_{k_2} - M_{k_1}), \cdots,
 (M_{K_m} - M_{k_{m-1}})\)</span> are independent.</p>
<p>Moreover, <span class="math inline">\(\Var(M_{k_{i+1}} - M_{k_i}) = k_{i+1} - k_i\)</span>.</p>
<p>The <strong>symmetric random walk is a martingale</strong>, i.e., <span class="math inline">\(\E[M_l\vert
 \F_k] = M_k\)</span> for <span class="math inline">\(k &lt; l\)</span>.</p>
<p>The <strong>quadratic variation</strong> of the symmetric random walk <span class="math inline">\([M, M]_K =
 \sum_1^k (M_j - M_{j-1})^2 = k\)</span>. Note that this property is also true for a general random walk (where <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are not necessarily the same.)</p></li>
<li><p><strong>Brownian motion</strong></p></li>
</ul>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
